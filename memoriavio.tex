%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Plantilla de memoria en LaTeX para la ETSIT - Universidad Rey Juan Carlos
%%
%% Por Gregorio Robles <grex arroba gsyc.urjc.es>
%%     Grupo de Sistemas y Comunicaciones
%%     Escuela Técnica Superior de Ingenieros de Telecomunicación
%%     Universidad Rey Juan Carlos
%% (muchas ideas tomadas de Internet, colegas del GSyC, antiguos alumnos...
%%  etc. Muchas gracias a todos)
%%
%% La última versión de esta plantilla está siempre disponible en:
%%     https://github.com/gregoriorobles/plantilla-memoria
%%
%% Para obtener PDF, ejecuta en la shell:
%%   make
%% (las imágenes deben ir en PNG o JPG)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper, 12pt]{book}
%\usepackage[T1]{fontenc}

\usepackage[a4paper, left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry}
\usepackage{times}
\usepackage[latin1]{inputenc}
%\usepackage[spanish]{babel} % Comenta esta línea si tu memoria es en inglés
\usepackage{url}
%\usepackage[dvipdfm]{graphicx}
\usepackage{graphicx}
\usepackage{float}  %% H para posicionar figuras
\usepackage[nottoc, notlot, notlof, notindex]{tocbibind} %% Opciones de índice
\usepackage{latexsym}  %% Logo LaTeX
\usepackage{subfig}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=red,
    filecolor=red,
    linkcolor=red,
    urlcolor=red
}

%Define the listing package
\usepackage{listings} %code highlighter
\usepackage{color} %use color
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
 
%Customize a bit the look
\lstset{ %
backgroundcolor=\color{white}, % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
basicstyle=\footnotesize, % the size of the fonts that are used for the code
breakatwhitespace=false, % sets if automatic breaks should only happen at whitespace
breaklines=true, % sets automatic line breaking
captionpos=b, % sets the caption-position to bottom
commentstyle=\color{mygreen}, % comment style
deletekeywords={...}, % if you want to delete keywords from the given language
escapeinside={\%*}{*)}, % if you want to add LaTeX within your code
extendedchars=true, % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
frame=single, % adds a frame around the code
keepspaces=true, % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
keywordstyle=\color{blue}, % keyword style
% language=Octave, % the language of the code
morekeywords={*,...}, % if you want to add more keywords to the set
numbers=left, % where to put the line-numbers; possible values are (none, left, right)
numbersep=5pt, % how far the line-numbers are from the code
numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
rulecolor=\color{black}, % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
showspaces=false, % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
showstringspaces=false, % underline spaces within strings only
showtabs=false, % show tabs within strings adding particular underscores
stepnumber=1, % the step between two line-numbers. If it's 1, each line will be numbered
stringstyle=\color{mymauve}, % string literal style
tabsize=2, % sets default tabsize to 2 spaces
title=\lstname % show the filename of files included with \lstinputlisting; also try caption instead of title
}
%END of listing package%
 
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}
 
%define Javascript language
\lstdefinelanguage{JavaScript}{
keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
keywordstyle=\color{blue}\bfseries,
ndkeywords={class, export, boolean, throw, implements, import, this},
ndkeywordstyle=\color{darkgray}\bfseries,
identifierstyle=\color{black},
sensitive=false,
comment=[l]{//},
morecomment=[s]{/*}{*/},
commentstyle=\color{purple}\ttfamily,
stringstyle=\color{red}\ttfamily,
morestring=[b]',
morestring=[b]"
}
 
\lstset{
language=JavaScript,
extendedchars=true,
basicstyle=\footnotesize\ttfamily,
showstringspaces=false,
showspaces=false,
numbers=left,
numberstyle=\footnotesize,
numbersep=9pt,
tabsize=2,
breaklines=true,
showtabs=false,
captionpos=b
}

\title{Thesis}
\author{Viorel Rusu}

\renewcommand{\baselinestretch}{1.5}  %% Interlineado

\begin{document}

%\renewcommand{\refname}{Bibliografía}  %% Renombrando
\renewcommand{\appendixname}{Appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PORTADA

\begin{titlepage}
\begin{center}
\begin{tabular}[c]{c c}
%\includegraphics[bb=0 0 194 352, scale=0.25]{logo} &
\includegraphics[scale=0.25]{img/logo_vect.png} &
\begin{tabular}[b]{l}
\Huge
\textsf{UNIVERSIDAD} \\
\Huge
\textsf{REY JUAN CARLOS} \\
\end{tabular}
\\
\end{tabular}

\vspace{3cm}

\Large
INGENIERÍA SUPERIOR DE TELECOMUNICACIONES + INGENIERÍA TÉCNICA EN INFORMÁTICA DE SISTEMAS

\vspace{0.4cm}

\large
Curso Académico 2016/2017

\vspace{0.8cm}

Trabajo Fin de Carrera

\vspace{2.5cm}

\LARGE
3D Charts visualizations in Kibana

\vspace{4cm}

\large
Autor : Viorel Rusu
Tutor : Dr. Jesús M. González Barahona
\end{center}
\end{titlepage}

\newpage
\mbox{}
\thispagestyle{empty} % para que no se numere esta pagina


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Para firmar
\clearpage
\pagenumbering{gobble}
\chapter*{}

\vspace{-4cm}
\begin{center}
\LARGE
\textbf{Proyecto Fin de Carrera}

\vspace{1cm}
\large
FIXME: Título

\vspace{1cm}
\large
\textbf{Autor :} FIXME \\
\textbf{Tutor :} Dr. Gregorio Robles Martínez

\end{center}

\vspace{1cm}
La defensa del presente Proyecto Fin de Carrera se realizó el día \qquad$\;\,$ de \qquad\qquad\qquad\qquad \newline de 20XX, siendo calificada por el siguiente tribunal:


\vspace{0.5cm}
\textbf{Presidente:}

\vspace{1.2cm}
\textbf{Secretario:}

\vspace{1.2cm}
\textbf{Vocal:}


\vspace{1.2cm}
y habiendo obtenido la siguiente calificación:

\vspace{1cm}
\textbf{Calificación:}


\vspace{1cm}
\begin{flushright}
Fuenlabrada, a \qquad$\;\,$ de \qquad\qquad\qquad\qquad de 20XX
\end{flushright}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Dedicatoria

\chapter*{}
\pagenumbering{Roman} % para comenzar la numeracion de paginas en numeros romanos
\begin{flushright}
\textit{Dedicado a \\
mi familia / mi abuelo / mi abuela}
\end{flushright}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Agradecimientos

\chapter*{Acknowledgment}
%\addcontentsline{toc}{chapter}{Agradecimientos} % si queremos que aparezca en el índice
\markboth{Acknowledgment}{Acknowledgment} % encabezado 

Many years have passed since I started my career. It has been a path in which joys and satisfaction have been mixed with moments of disappointment and failure. Looking backwards, I cannot say it was easy at all. But, at the same time I can say with all conviction that now I am stronger, I have become a better person. And it was worth it. And here I am, crossing the finish line. I wouldn't have been able to make this alone. I am very grateful to God in first place. I have to thank my mother for supporting me through all these years, for her care and unconditional love. Thanks to my family, for being there when I needed some encouragement. And thanks to my girlfriend, just for being there when I needed a shoulder to cry on. Last but not least, I am really thankful for my tutor, Jesús, for always being there when I needed him and for his comprehension and guidance through this project.

I will end this section by mentioning an almost 2000 years old verse:

"I can do all things through Christ who strengthens me." ~ Saul of Tarsus 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen

\chapter*{Resumen}
%\addcontentsline{toc}{chapter}{Resumen} % si queremos que aparezca en el índice
\markboth{RESUMEN}{RESUMEN} % encabezado

Este proyecto tiene como objetivo integrar un sistema de visualización de datos en 3 dimensiones en un sistema complejo de visualización e interacción de datos. Como sistema complejo de visualización de datos se ha utilizado Kibana y el motor de bases de datos es ElasticSearch. El sistema de visualización de gráficos que se ha integrado es la biblioteca threeDC.js. El resultado de esta integración tiene forma de plugin fácilmente instalable en Kibana.

Este plugin, una vez instalado, permite añadir 3 tipos de visualizaciones nuevas a las que Kibana ya tenía. De esta manera, podemos integrar en un único cuadro de mando gráficos tanto en dos dimensiones con las visualizaciones predefinidas por Kibana como en tres, con las visualizaciones desarrolladas en este proyecto.

Para lograr este objetivo se ha programado casi exclusivamente en Javascript, con algo de HTML5. Como tecnologías Javascript a destacar hay que mencionar AngularJS, todo el código Javascript está estructurado así y se han utilizado las funcionalidades que ofrece AngularJS. Se ha utilizado indirectamente un motor gráfico potente, webGL, para representar escenas tridimensionales complejas. Esto se ha hecho a través de la librería Javascript three.js y su extensión threeDC.js.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen en inglés

\chapter*{Summary}
%\addcontentsline{toc}{chapter}{Summary} % si queremos que aparezca en el índice
\markboth{SUMMARY}{SUMMARY} % encabezado

This project aims to integrate a 3D data visualization system into a complex data visualization and interaction system. As a complex data visualization system Kibana has been used and the database engine is ElasticSearch. The graphics display system that has been integrated is threeDC.js library. The result of this integration is in the form of an easily installable plugin in Kibana.

This plugin, once installed, allows to add 3 types of new visualizations to the already existing visualizations in Kibana. In this way, we can integrate in a single dashboard both 2D charts and 3D charts, with the visualizations developed in this project.

To achieve this goal Javascript programming language has been almost exclusively used, with some HTML5. As Javascript technologies to highlight we must mention AngularJS, all Javascript code is structured using this paradigma and all the features offered by AngularJS have been used. A powerful graphics engine, webGL, has been indirectly used to represent complex three-dimensional scenes through three.js javascript library and threeDC.js extension.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ÍNDICES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Las buenas noticias es que los índices se generan automáticamente.
% Lo único que tienes que hacer es elegir cuáles quieren que se generen,
% y comentar/descomentar esa instrucción de LaTeX.

%%%% Índice de contenidos
\tableofcontents 
%%%% Índice de figuras
\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de figuras} % para que aparezca en el indice de contenidos
\listoffigures % indice de figuras
%%%% Índice de tablas
%\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de tablas} % para que aparezca en el indice de contenidos
%\listoftables % indice de tablas


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCCIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Introduction}
\label{sec:intro} % etiqueta para poder referenciar luego en el texto con ~\ref{sec:intro}
\pagenumbering{arabic} % para empezar la numeración de página con números

We live in a world of data. Data of all sorts: sensors, logs, statistics, different company data. Specifically, in the world of software projects, we also start to have thousands and thousands of data Terabytes. We should not be surprized, a single software project may have millions of lines of code, written by thousands different programmers, having contributions from houndreds of different companies, with thousands of different versions... ok, you get the idea. The problem is we, humans, lose perspective if we only observe that raw data, and it becomes completely useless. We just can't see the forest for the trees.

\section{The problem}
\label{sec: TheProblem}

From the previous paragraph, it seems obvious that what is needed is to get simpler data from that huge amount of data. What is needed is to analyze that data in some way, organize and show it so we, humans, could have an eagle view just by a glance. That way, we could draw conclusions about that information and make better decisions, improving our world.

In the last years, many different projects have arisen with this goal in mind: provide tools that help us analyze huge amounts of data and represent it somehow. We are talking about projects such as business intelligence projects, data mining, real-time analytics and visualizations. Some of them are real Big Data projects, some of them don't have in scope such a big amount of data so we can't call them that way.

Specifically, what we want is to build different visualizations, or dashboards, of our software development data. We are applying our data analysis and visualizations to software projects in particular, but really we could apply it to any other kind of data. Out there we can find many tools to achieve our goals. There are many different solutions to the mentioned problem of respresenting data. What we want is a solution that lives in the browser. Somehow, we want the final user to interact with his browser and seeing easily different visualizations of his own data, in a new way it hasn't been shown before. We want to make our contribution to this world and make it available for everyone, we want it to be open source.


\section{The solution}
\label{sec:TheSolution}

We decided to use Kibana\footnote{\url{https://www.elastic.co/products/kibana}}: an open source analytics and visualization platform designed to work with Elasticsearch\footnote{\url{https://www.elastic.co/products/elasticsearch}}. Elasticsearch is a highly scalable open-source full-text search and analytics engine. It allows us to store, search, and analyze big volumes of data quickly and in near real time.

Kibana is a very new technology, fully under development by the time this project was realized. It provides single visualizations of different types, like pie or bar charts. Then, it is possible to save and load this visualizations in a dynamic dashboard. This is an interactive dashboard, allowing us to move each separate visualization around, and applying different filters to all data just by interacting with a single visualization for example. This makes it really easy to understand large volumes of data. We can quickly create dynamic dashboards that display changes to Elasticsearch queries in real time. All this features made Kibana a very good choice.

The problem with Kibana is that it has a very limited number of visualizations. Kibana team is aware of this problem and they encourage independent developers to develop their own visualizations and make it public to the community. And this is achieved developing a plugin for Kibana. Official documentation on how to create a custom plugin is poor, but luckily independent developers have succeeded and published the process. With this information, and the information we can obtain of standard plugins by reverse-engineering, reading source code, we are able to create a new plugin.

We saw that basic 2D charts are already available in Kibana, and other developers were already working in adding more variety to it. So a good idea would be to represent the data in a whole new way for Kibana, under the form of 3D charts. There are not many 3D libraries out there written in Javascript that allow us to represent 3D functional data, and we wanted to promote the use of a new library a student at Universidad Rey Juan Carlos developed as his thesis, being in touch with the developer in order to add new functionality and report bugs.

In order to sum it up, we can express our solution with the following words: it is going to take the form of an easy-install plugin fully-integrated in Kibana, containing different 3D visualizations.


\section{Objectives}
\label{sec:Objectives}


\begin{enumerate}

\item- Use Kibana integrated tools to retrieve the data we need from elasticsearch.
\item- Build some new 3D visualizations
\item- Integrate threedc.js 3D scenes in Kibana visualization
\item- Integrate threedc.js visualization in Kibana dashboard
\item- Add custom events to threedc charts in order to filter data on click
\item- Help to improve threedc.js library by reporting bugs, adding an interface for custom data and for custom events.

\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ESTADO DEL ARTE %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TECNOLOGÍAS USADAS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Context and Used technologies}
\label{sec:technologies}

\section{HTML5}

HTML5 is a markup language used for structuring and presenting content on the World Wide Web. It was finalized, and published, on 28 October 2014 by the World Wide Web Consortium (W3C) This is the fifth revision of the HTML standard since the inception of the World Wide Web. The previous version, HTML 4, was standardized in 1997.

Its core aims are to improve the language with support for the latest multimedia while keeping it easily readable by humans and consistently understood by computers and devices (web browsers, parsers, etc.). HTML5 is intended to subsume not only HTML 4, but also XHTML 1 and DOM Level 2 HTML.

In particular, HTML5 adds many new syntactic features. These include the new video, audio and canvas elements, as well as the integration of scalable vector graphics (SVG) content (replacing generic object tags) and MathML for mathematical formulas. These features are designed to make it easy to include and handle multimedia and graphical content on the web without having to resort to proprietary plugins and APIs. Other new page structure elements, such as main, section, article, header, footer, aside, nav and figure, are designed to enrich the semantic content of documents. New attributes have been introduced, some elements and attributes have been removed and some elements, such as a, cite and menu> have been changed, redefined or standardized. The APIs and Document Object Model (DOM) are no longer afterthoughts, but are fundamental parts of the HTML5 specification.HTML5 also defines in some detail the required processing for invalid documents so that syntax errors will be treated uniformly by all conforming browsers and other user agents.

\section{Javascript} 

JavaScript is a high-level, dynamic, untyped, and interpreted programming language.It has been standardized in the ECMAScript language specification. Alongside HTML and CSS, it is one of the three essential technologies of World Wide Web content production; the majority of websites employ it and it is supported by all modern Web browsers without plug-ins.JavaScript is prototype-based with first-class functions, making it a multi-paradigm language, supporting object-oriented,imperative, and functional programming styles.It has an API for working with text, arrays, dates and regular expressions, but does not include any I/O, such as networking, storage, or graphics facilities, relying for these upon the host environment in which it is embedded.

Despite some naming, syntactic, and standard library similarities, JavaScript and Java are otherwise unrelated and have very different semantics. The syntax of JavaScript is actually derived from C, while the semantics and design are influenced by the Self and Scheme programming languages.

JavaScript is also used in environments that are not Web-based, such as PDF documents, site-specific browsers, and desktop widgets. Newer and faster JavaScript virtual machines (VMs) and platforms built upon them have also increased the popularity of JavaScript for server-side Web applications. On the client side, JavaScript has been traditionally implemented as an interpreted language, but more recent browsers perform just-in-time compilation. It is also used in game development, the creation of desktop and mobile applications, and server-side network programming with runtime environments such as Node.js.

These are Javascript main features:

\begin{itemize}  
\item \underline{Imperative and structured}: 
JavaScript supports much of the structured programming syntax from C (e.g., if statements, while loops, switch statements, do while loops, etc.). One partial exception is scoping: JavaScript originally had only function scoping with var. ECMAScript 2015 adds a let keyword for block scoping, meaning JavaScript now has both function and block scoping. Like C, JavaScript makes a distinction between expressions and statements. One syntactic difference from C is automatic semicolon insertion, which allows the semicolons that would normally terminate statements to be omitted.
\item \underline{Dynamic}:
As with most scripting languages, JavaScript is dynamically typed; a type is associated with each value, rather than just with each expression. For example, a variable that is at one time bound to a number may later be re-bound to a string. JavaScript supports various ways to test the type of an object, including duck typing.
JavaScript includes an eval function that can execute statements provided as strings at run-time.
\item \underline{Prototype-based (Object-oriented)}:
JavaScript is almost entirely object-based. In JavaScript, an object is an associative array, augmented with a prototype (see below); each string key provides the name for an object property, and there are two syntactical ways to specify such a name: dot notation (obj.x = 10) and bracket notation (obj['x'] = 10). A property may be added, rebound, or deleted at run-time. Most properties of an object (and any property that belongs to an object's prototype inheritance chain) can be enumerated using a for...in loop.

JavaScript has a small number of built-in objects, including Function and Date.
\item \underline{Functional}:
A function is first-class; a function is considered to be an object. As such, a function may have properties and methods, such as .call() and .bind().A nested function is a function defined within another function. It is created each time the outer function is invoked. In addition, each nested function forms a lexical closure: The lexical scope of the outer function (including any constant, local variable, or argument value) becomes part of the internal state of each inner function object, even after execution of the outer function concludes.JavaScript also supports anonymous functions.
\end{itemize}

\section{ElasticSearch}

Elasticsearch is a distributed, scalable, real-time search and analytics engine. It makes it possible to search, analyze, and explore data at a speed and at a scale never before possible. It is used for full-text search, structured search, analytics, and all three in combination.

Elasticsearch is an open-source search engine built on top of Apache Lucene?, a full-text search-engine library. Lucene is arguably the most advanced, high-performance, and fully featured search engine library in existence today?both open source and proprietary. Elasticsearch is written in Java and uses Lucene internally for all of its indexing and searching, but it aims to make full-text search easy by hiding the complexities of Lucene behind a simple, coherent, RESTful API.

\subsection{Key concepts}

\begin{itemize}
\item \underline{Document}

A document is a basic unit of information that can be indexed. This document is expressed in JSON. Within an index, as many documents as it's wanted may be stored. Although a document physically resides in an index, a document actually must be assigned to a type inside an index.

\item \underline{Index}

An index is a collection of documents that have somewhat similar characteristics. An index is identified by a name (that must be all lowercase) and this name is used to refer to the index when performing indexing, search, update, and delete operations against the documents in it.

\item \underline{Type}

Within an index, one or more types can be defined. A type is a logical category/partition of the index whose semantics is completely up to the user. In general, a type is defined for documents that have a set of common fields.

\item \underline{Node}

A node is a single server that is part of the cluster, stores the data, and participates in the cluster?s indexing and search capabilities. Just like a cluster, a node is identified by a name which by default is a random Universally Unique IDentifier (UUID) that is assigned to the node at startup. Any node name can be defined if the default is not wanted. This name is important for administration purposes where it is needed to identify which servers in the network correspond to which nodes in the Elasticsearch cluster.

\item \underline{Cluster}

A cluster is a collection of one or more nodes (servers) that together holds the entire data and provides federated indexing and search capabilities across all nodes. A cluster is identified by a unique name which by default is "elasticsearch". This name is important because a node can only be part of a cluster if the node is set up to join the cluster by its name. 

\end{itemize}

\subsection{Data interaction}

Elasticsearch provides a rich, flexible, query language called the query DSL, which allows us to build much more complicated, robust queries. The domain-specific language (DSL) is specified using a JSON request body. The queries and all interaction with elasticsearch has the next aspect:

\begin{lstlisting}
GET /megacorp/employee/_search
{"query" : {"match" : {"last_name" : "Smith"}}}
\end{lstlisting}

Through these DSL queries any database operation can be performed. Of course, elasticSearch has APIs for the most known languages, so it is possible to make queries from other programming languages.

In this project, an elasticsearch server has been set up and all elasticsearch queries have been made indirectly through Kibana. This means that, by properly using Kibana functions and methods, it is possible to avoid manually having to make queries. 

\section{Kibana}

Kibana is an open source analytics and visualization platform for Elasticsearch. It provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Kibana is used to search, view, and interact with data stored in Elasticsearch indices. Advanced data analysis and visualization can be easily performed in a variety of charts, tables and map. Kibana makes it easy to understand large volumes of data.

Next, the most important pages in Kibana will be explained. Then, we will go through other Kibana worth-mentioning features.

In figure \ref{fig:kibana_tabs} Kibana pages are shown. These three are used in 99\% of the cases when working with Kibana:

\begin{figure}
  \centering
  \includegraphics[height=12cm, keepaspectratio]{img/kibana_tabs}
  \caption{Kibana pages}
  \label{fig:kibana_tabs}
\end{figure}

\begin{itemize}
\item Discover. Data can be interactively explored in this page. We have access to every document in every index that matches the selected index pattern. We can submit search queries, filter the search results, and view document data. We can also see the number of documents that match the search query and get field value statistics. If a time field is configured for the selected index pattern, the distribution of documents over time is displayed in a histogram at the top of the page.

\item Visualize. Visualize enables us to create visualizations of the data in our Elasticsearch indices. We can then build dashboards that display related visualizations. Kibana visualizations are based on Elasticsearch queries. By using a series of Elasticsearch aggregations to extract and process the data, we can create charts that show the trends, spikes, and dips we need to know about.
We can create visualizations from a search saved from Discover or start with a new search query. There is a limited types of visualizations available in Kibana: Area chart, Data table, Line chart, Markdown widget, Metric, Pie chart, Tag cloud, Tile map, Timeseries, Vertical bar chart There are also independent developers that have created some more visualizations. The elastic team maintains an updated list of these plugins\footnote{\url{https://www.elastic.co/guide/en/kibana/current/known-plugins.html}}

\item Dashboard. Undoubtely, the most powerful feature of Kibana. It allows the user to display a collection of saved visualizations. These visualizations can be arranged and resized as needed. Dashboards can also be saved so they can be reloaded and shared. A quite complete dashboard can be seen in figure \ref{fig:complete_dashboard_kibana}.
\end{itemize}

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/complete_dashboard_kibana}
  \caption{Example dashboard in Kibana}
  \label{fig:complete_dashboard_kibana}
\end{figure}

Some other key features of Kibana are the filters. Filters can easily be added to the data using the always-displayed top right time filter or by clicking some data in the Discover page, or even by clicking different parts of some visualizations. In dashboards, added filters on the go make all visualizations to refresh in order to display the new filtered data.

\section{AngularJS}

AngularJS is a structural framework for dynamic web apps. It lets us use HTML as a template language and lets us extend HTML syntax to clearly express our application components. AngularJS data binding and dependency injection eliminate much of the code we would otherwise have to write. And it all happens within the browser, making it an ideal partner with any server technology. AngularJS teaches the browser new syntax through a construct we call directives. Examples include:

\begin{itemize}
\item Data binding.
\item DOM control structures for repeating, showing and hiding DOM fragments.
\item Support for forms and form validation.
\item Attaching new behavior to DOM elements, such as DOM event handling.
\item Grouping of HTML into reusable components.
\end{itemize}

AngularJS is not a single piece in the overall puzzle of building the client-side of a web application. It handles all of the DOM and AJAX glue code you once wrote by hand and puts it in a well-defined structure. This makes AngularJS opinionated about how a CRUD (Create, Read, Update, Delete) application should be built. But while it is opinionated, it also tries to make sure that its opinion is just a starting point you can easily change.

AngularJS simplifies application development by presenting a higher level of abstraction to
the developer. Like any abstraction, it comes at a cost of flexibility. In other words, not every
app is a good fit for Angular. AngularJS was built with the CRUD application in mind. Luckily
CRUD applications represent the majority of web applications. To understand what AngularJS
is good at, though, it helps to understand when an app is not a good fit for Angular.

Games and GUI editors are examples of applications with intensive and tricky DOM ma-
nipulation. These kinds of apps are different from CRUD apps, and as a result are probably
not a good fit for Angular. In these cases it may be better to use a library with a lower level of
abstraction, such as jQuery.

Kibana exploits AngularJS power in order to build its pages. Also, in order to develop this project, AngularJS and all its features had to be used (scopes, modules, directives,...).

\section{webGL}

WebGL (Web Graphics Library) is a cross-platform, royalty-free web standard for a low-level 3D graphics JavaScript API for rendering interactive 3D computer graphics and 2D graphics within any compatible web browser without the use of plugins. WebGL is integrated completely into all the web standards of the browser allowing GPU accelerated usage of physics and image processing and effects as part of the web page canvas. WebGL elements can be mixed with other HTML elements and composited with other parts of the page or page background.WebGL programs consist of control code written in JavaScript and shader code that is executed on a computer's Graphics Processing Unit (GPU). WebGL is designed and maintained by the non-profit Khronos Group.

WebGL is based on OpenGL ES 2.0 and provides an API for 3D graphics.It uses the HTML5 canvas element and the access is made using Document Object Model interfaces. Automatic memory management is provided as part of the JavaScript language.

The WebGL API may be too tedious to use directly without some utility libraries, which for example set up typical view transformation shaders (e.g. for view frustum). Loading scene graphs and 3D objects in the popular industry formats is also not directly provided for. JavaScript libraries have been built (or sometimes ported to WebGL) to provide the additional functionality.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/webglexample}
  \caption{A webgl example - water simulation, a Chrome Experiment}
  \label{fig:webglexample}
\end{figure}

As WebGL is an advanced technology designed to work directly with the Graphics Processing Unit, it is hard to code compared to other web standards which are more accesibles. This is the reason why many JavaScript libraries have appeared, to solve this problem. The most famous webGL library in terms of users is Three.js. It is light and not so complex compared with the original webGL specification. This is also the library that has been used in this project, and we will explain this library in the next section.

\section{Three.js} 

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/threeexample}
  \caption{A three.js example - Helloracer game}
  \label{fig:threeexample}
\end{figure}

\section{ThreeDC.js}

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/threedcexample}
  \caption{3D charts built with threeDC}
  \label{fig:threedcexample}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DISEÑO E IMPLEMENTACIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Development}

\section{SCRUM Methodology}
\label{sec:scrum}

Scrum is an iterative and incremental agile software development framework for managing product development. In software projects, time optimization, team coordination, resources managing and task assigning is crucial in order to reach a final working product and specially fast working intermediate versions of the product. It is based on these intermediate versions delivery and offers great agility and flexibility, as small goals are set on the way, after each previous goal has been reached.

There are three basic roles in this methodology:

\begin{itemize}

\item \textbf{Product Owner}: represents the voice of the customer and those initially interested directly in the project. This role is in charge of defining the product and its functionality. He focuses on the business side of product development. He establishes and negotiates priorities and steers the product in the right direction.

\item \textbf{Development Team}: responsible for delivering shippable increments at the end of each intermediate version of the product. They do all the technical work: analyse, design, develop, test and document the product.

\item \textbf{Scrum Master}: ensures that the Scrum Methodology is correctly followed. He coaches the team and product owner on the scrum process and looks for ways to improve its implementability in that particular project. He also looks and resolves impediments and distractions of the development team and keeps it focused on the key tasks. This role must not be mistaken with a project manager. A scrum master doesn't have people management responsabilities. A project manager doesn't really have a place in this methodology, the development team and scrum master are self-organizational.

\end{itemize}

In the Scrum Methodology, work is confined to repeatable work cycles known as sprints or iterations. Scrum is iterative and incremental. This means that product is always build on previous iteration, adding new features each time. During each sprint, the development team creates a potentially shippable product increment.


%\ref{fig:scrum-workflow}
\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/scrum-workflow}
  \caption{Scrum workflow}
  \label{fig:scrum-workflow}
\end{figure}


In each sprint a Sprint Backlog is defined. It collects all the tasks that are needed to be done and who is going to do them, as well as an estimation for the time needed for each task to be completed.

A natural question comes in mind at this point: can this methodology be at any help in a software project developed entirely by a single person? Although Scrum was not designed for this particular simple case, it can be very helpful. There won't be a Product Owner, a Scrum aster and a Team as such, but the methodology remains useful. This is because its main advantages are based on its flexibility and product control, and this is obtained even if the project is entirely developed by a single person! It provides control, adaptability and flexibility independently of the size of the project and number of people involved.

In this project, following Sprints have been defined and developed:

\begin{enumerate}

\item \textbf{Sprint 0}: Investigation and technologies exploration
\item \textbf{Sprint 1}: First systems using elasticsearch, threeDC charts and Kibana custom plugins
\item \textbf{Sprint 2}: 3D Basic Pie Visualization
\item \textbf{Sprint 3}: Data treatment
\item \textbf{Sprint 4}: Kibana Integration

\end{enumerate}

\section{Sprint 0}

\subsection{Primitive dashboard}
\label{subsec:old-pfc}

It is worth mentioning that the Kibana-elasticSearch solution was not clear from the beginning of this project. As the main objectives were to build a customizable dashboard living in the web browser, with open source projects data, a completely different solution was started. In this section, an overview of this paralell solution will be presented, even if this path has been abandoned on our way in order to embrace Kibana.

The solution we had in mind had the following architecture:

%\ref{fig:arquitectura-old-pfc}
\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/arquitectura-old-pfc}
  \caption{Proposed architecture}
  \label{fig:arquitectura-old-pfc}
\end{figure}

A MySQL database stores the information about software projects. A Django Server is set up in order to retrieve this information and serve it to the client as the browser demands it. Finally, the browser executes and plots the data. This is the basic workflow in this architecture.

The final result, in a basic version, can be seen in figure \ref{img:old-pfc-dygraph}

%\ref{fig:old-pfc-dygraph}
\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/old-pfc-dygraph}
  \caption{Simple browser visualization of commits timeseries}
  \label{fig:old-pfc-dygraph}
\end{figure}

The technologies used to get to this solution were many. We will make a brief mention of the most important:

\begin{itemize}
\item Django Server: where all the application logic lives
\item AngularJS as the front-end web application framework to provide a Single Page Application
\item Twitter Bootstrap for the front-end design
\item MySQL as database
\item Dygraphs as the Javascript library to plot our data
\end{itemize}

A dynamic dashboard was to be created using more Javascript libraries. This is a complex and tedious task. But most importantly, it is an unnecesary task. In the last years, great solutions have been given to this problem. Kibana is one of them. By worrying only about a certain visualization, if we do it well, Kibana will integrate it perfectly in its own dashboard, where this visualization lives side by side and interacts with other visualizations developed. This has great advantages:

\begin{itemize}

\item We can focus on data analysis and a visualization each time, as we don't have to worry too much about integrating all the visualizations in a dashboard. Kibana does this in a beautiful way.
\item We can generalize the use of our product and give it a great platform where to live and be known. With Kibana, our database can be anything, not only a certain type of data with closed schemas. 

And this is enough reasons to abandon the primitive solution and decide to begin with Kibana. In the rest of this paper, we won't mention this primitive solution anymore, as it died on our way to a better solution. It provided a better comprehension of the problem and the different solutions and learning was important too, as many of these technologies and concepts are used in the rest of the project.

\end{itemize}

\subsection{Setting up elasticSearch and Kibana}
\label{subsec:kibana-es}

Once it was clear this project was about a Kibana plugin, we started getting familiarized with these technologies.

We will start with elasticSearch. I downloaded the latest client and started storing, exploring and modifying data. The download and installation is easy, it is just needed to download an elasticSearch version from https://www.elastic.co/downloads/elasticsearch. I opted for downloading the tar version. Once uncompressed, elastic search is run by executing bin/elasticsearch contained in the folder. This sets up an elasticSearch server, listening at port 9200. No additional configuration was needed.

ElasticSearch provides a REST API to interact with the database. Every operation with elasticSearch engine will be done through this API. We use 'curl' in order to make HTTP requests to a server from command line. For example, we use the following methods:

\begin{lstlisting}[language=bash]
curl -XGET 'localhost:9200/_cat/indices?v'
curl -XPUT 'localhost:9200/customer?pretty': to create a new index
\end{lstlisting}

The first command shows all existing indexes while the second creates a new index in our elasticSearch database.
 
Once indexes are created, we can put documents inside them, like this:

\begin{lstlisting}
curl -XPUT 'localhost:9200/customer/external/1?pretty
{
  "name": "John Doe"
}'
\end{lstlisting}
Every operation or query we need to perform is done through this HTTP API.

These are basic operations. What we want is to work with a great amount of data. We can find test data for elasticSearch out there but we wanted to analyze specifically open source projects data. In my github\footnote{\url{https://github.com/virusu/Docs/blob/master/opnfv_git_es.json.gz}} you cand find a JSON file with data about opnfv project in github, already in a elasticSearch format. We load this file into elasticSearch using taskrabbit tool for managing indexes: 'elastic-dump'\footnote{\url{https://github.com/taskrabbit/elasticsearch-dump}}:

\begin{lstlisting}
elasticdump --input=opnfv_git_es.json --output=http://localhost:9200/commits-index
\end{lstlisting}
This will be the index we will work with in the rest of the project.

Next, we install Kibana. We decided to install the development version directly, following the instructions that elastic team officially gives to developers in "CONTRIBUTING.md"\footnote{\url{https://github.com/elastic/kibana/blob/master/CONTRIBUTING.md}}. The latest version was an alpha version of Kibana 5.0.0, and this will be the version we work through the rest of the project. This is not such a simple process, and can bring some little descriptive errors like in my case when running kibana in development mode with "npm start" inside kibana directory. This error was the following:
\begin{lstlisting}
failed to watch files! Error: watch /home/vio/kibanadev2/src/plugins ENOSPC at exports._errnoException (util.js:870:11)
\end{lstlisting}
Investigating about the error, it was because Kibana run in dev mode requires watching a hundreds of files at the same time, looking for changes and recompiling everything to bring the new changes into the running kibana instance. What I did is to permanently modify the maximum notify watchers variable in sysctl:

\begin{lstlisting}
echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p
\end{lstlisting}

Once Kibana runs correctly, the first time we access it it will ask us to configure an index pattern. We will do this and at this point everything is set up to start focusing on our plugin development.


\section{Sprint 1} First systems with Kibana custom plugins, elasticSearch and threeDC charts

The main goal in this sprint is to build the first working systems with the main technologies involved in this project: Kibana, elasticSearch and threeDC. A separate and very basic server interacting with elasticsearch will be built in first place. We take advantage of having this server serving a page to also show a basic threeDC chart, killing two birds with one stone.  In second place, Kibana will enter into action and it will act as the server, interacting with elasticsearch to show up some basic data by itself.

\subsection{Separate server showing up ES data and a threeDC chart}

This is the only section where we focus on anything separately from Kibana. What we aim here is to have a simple server having two different separate functionalities. On the one side, we want this server to interact with elasticSearch on its own, without Kibana. We take advantage of this server and take into action the angularJS framework. On the other hand, we want it to show threeDC charts, loading all the libraries needed. Finally, a client through a browser will view a single page with two divs, one containing some sort of elasticSearch data and the other plotting some sort of threeDC charts. This will set the basis for a much more complex server like Kibana, with much more complex queries to elasticSearch and more issues with the threeeDC library.

First of all, we need a server. We decided to use the python built-in HTTP server for its simplicity. Just by running the server in a certain folder, it automatically serves the files in that folder through default port 8000. The command used for this couldn't be simpler:

\begin{lstlisting}
python -m SimpleHTTPServer
\end{lstlisting}

So whatever is put in an index.html file, the server serves it. We start creating and modifying this file, which you can completely see at the appendix \ref{sec:appendix} of this paper. You can see the final result of this Sprint in figure \ref{fig:index-ES-threeDC}.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/index-ES-threeDC}
  \caption{Html page showing the result of an ES query and a threeDC chart}
  \label{fig:index-ES-threeDC}
\end{figure}

Now we will focus on the two functionalities, on separate.

In the first place, let's focus on elasticSearch interaction. We need a way to interact with elasticSearch. Elastic team provides different APIs for this, one for each of the main programming languages. As it's expected, there is one for Javascript. We will use the Angular Build API. So we do the following in our case.

Inside the angular module app, we create a service named client which we can use directly to make queries from the angular controller.

\begin{lstlisting}[language=JavaScript]
    ExampleApp.service('client', function (esFactory) {
      return esFactory({
        host: 'localhost:9200',
        apiVersion: '2.3',
        log: 'trace'
      });
    });
\end{lstlisting}

Now, in the controller, we call a method of this API to retrieve some information from elasticSearch. At this point, it is not important what kind of information we retrieve. For example, we can call the client.state method\footnote{\url{https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/api-reference.html\#api-cluster-state}}, which is used to get comprehensive details about the state of the whole cluster.

\begin{lstlisting}
      client.cluster.state({
        metric: [
          'cluster_name',
          'nodes',
          'master_node',
          'version'
        ]
        })
      .then(function (resp) {
        $scope.clusterState = resp;
        }
\end{lstlisting}

Then, the result is attached to the scope so it is easy to print this result directly from the html through angular. The result can be seen in the first section of the previous figure \ref{fig:index-ES-threeDC}. The complete code in detail can also be found in Appendix \ref{sec:script.js}.

In the second place, we will focus on building our first real threeDC graph. In the next paragraphs, only main scene scheleton will be described. Details and secondary commentaries will be left for the reader to investigate in Appendix \ref{sec:script.js}.

First, we create all the three.js objects needed for a scene to correctly be visualized: camera, renderers and light:

\begin{lstlisting}
      // set up camera
   camera = new THREE.PerspectiveCamera( VIEW_ANGLE, ASPECT, NEAR, FAR);
   // add the camera to the scene
   scene.add(camera);
   // the camera defaults to position (0,0,0)
   //    so pull it back (z = 400) and up (y = 100) and set the angle towards the scene origin
   camera.position.set(0,150,400);
   camera.lookAt(scene.position);

   renderer = new THREE.WebGLRenderer( {antialias:true} );
   renderer.setSize(SCREEN_WIDTH, SCREEN_HEIGHT);
   renderer.setClearColor( 0xd8d8d8 );
   
   var light = new THREE.PointLight(0xffffff,0.8);
   light.position.set(0,200,250);
   scene.add(light);
\end{lstlisting}

We get into threeDC library now. We pass all this 'three' elements to the threeDC library, to initialize a threeDC scene. Next, we create for example a 'pointsCloudChart' object, which paints an entire cloud made of points. In this case, we just use random data to paint that object. 

\begin{lstlisting}
  THREEDC.initializer(camera,scene,renderer,container);

  var cloud= THREEDC.pointsCloudChart([0,0,0]);
  cloud.getPoints(getRandomPoints(1000));

  THREEDC.renderAll();
\end{lstlisting}

The animate loop can't be forgotten, it is where all the updates and renders itself to the infinite. This function is called only once from the main code, but it will execute itself over and over again.

\begin{lstlisting}
function animate()
{
   requestAnimationFrame( animate );
   renderer.render( scene, camera );
   THREEDC.controls.update();
}
\end{lstlisting}

With these basic structure (threeDC, elasticSearch and angularJS) we can start getting at work with Kibana, which undoubtely is the titan  of this paper.

\subsection{Simple elasticSearch query and visualization in Kibana custom plugin}

In this section a new app will be created inside Kibana and elasticSearch will be queried from this app. We will make this query the simplest we can, for example querying the total number of documents in our index.

This will be the basic structure of our application:

\begin{lstlisting}
export default function (kibana) {
  return new kibana.Plugin({
    require: ['elasticsearch'],

    uiExports: {
      
      app: {
        title: 'My new app plugin',
        description: 'my first elasticsearch requests in background',
        main: 'plugins/elasticsearch_status_vio/app'
      }
    }
});
\end{lstlisting}

We must load the elasticsearch module here, by specifying it in the require array. This module will be necessary to make elasticsearch queries, as we will do later in this sprint. The rest of the parameters speak on their on: title, description and main file. The way we specify that this is not a visualization type to Kibana is by specifying this inside the uiExports with the 'app' key instead of 'visTypes' as done in the previous sprint for example.

Next, we need to query elasticSearch in some way. We don't want to use the javascript API, this would totally ignore Kibana and is not a clean solution. We want to use it through Kibana, and make Kibana do the queries to elasticsearch, through the elasticsearch module. This is the clean solution. In order to do this, we create a new Kibana Server API in the following way:

\begin{lstlisting}
import api from './server/routes/elasticsearch_routes';

    init(server, options) {
      // Add server routes and initalize the plugin here
      api(server);
    } 
\end{lstlisting}

The init method adds a new server API to Kibana. In the api file, we specify the api calls we want to define. In our case, we define the /ncommits GET server API call in the following way:

\begin{lstlisting}
export default function (server) {
  let call = server.plugins.elasticsearch.callWithRequest;
  server.route({
    path: '/api/elasticsearch_status/ncommits',
    method: 'GET',
    handler(req, reply) {
      call(req, 'count',{index: 'commits-index'}).then(function (response) {
        // Return just the names of all indices to the client.
        reply(response.count);
      });
    }
  });
}
\end{lstlisting}

The elasticsearch callWithRequest utility must be used in order to access elasticSearch. This method receives as parameters the request from our API (req) and then the name of the function from the elasticSearch Javascript Client to be called. In our case, we use the 'count' method to count the total documents in the commits-index. This method returns a promise that will be resolved with the response from Elasticsearch, and we only have to access the 'count' parameter from the response in order to get the answer returned from elasticSearch to our query.

For routing between pages (in this case it will be only one page), we have to explicitly enable uiRoutes and define our route in our app.js file:

\begin{lstlisting}
uiRoutes.enable();
.when('/ncommits', {
  template: ncommitsTemplate,
  controller:'elasticsearchNCommitsController',
  controllerAs: 'ctrl'
});

uiModules
.get('app/elasticsearch_status_vio', [])
.controller('elasticsearchNCommitsController', function ($http) {
  $http.get('../api/elasticsearch_status/ncommits').then((response) => {
    this.ncommits = response.data;
  });
});
\end{lstlisting}

For a detailed explanation on routes please consult the excellent Tim Roes tutorial about writing  custom applications(1), in which this sprint was based.

Finally, we define the ncommitsTemplate mentioned as follows:

\begin{lstlisting}
<div class="container">
  <div class="row">
    <div class="col-12-sm">
			<a href="#/">Index list</a>
      <h1>Number of commits in commits_index: {{ ctrl.ncommits }}</h1></div></div></div>
\end{lstlisting}

The final result can be seen in Fig \ref{fig:elasticsearch-app-ncommits}.

\begin{figure}
  \centering
  \includegraphics[width=18cm, keepaspectratio]{img/elasticsearch-app-ncommits}
  \caption{Custom app plugin result}
  \label{fig:elasticsearch-app-ncommits}
\end{figure}



\section{Sprint 2: 3D Basic Pie Visualization}

\subsection{Hello World visualization plugin}

In this section, a very basic plugin in Kibana will be built from scratch. The final result can be seen in figure XXX

In Kibana, developed plugins go into Kibana/plugins/ directory. The first thing to know about Kibana plugins is that every plugin is actually a npm module. Like every npm module, two basic files need to be created:

\begin{itemize}

\item package.json. We specify our plugin name here.

\begin{lstlisting}
{
  "name": "sprint2_plugin",
  "version": "5.0.0"
}
\end{lstlisting}

\item index.js. Here, our module has to instantiate a new instance of Kibana plugin, creating a new plugin of type 'visualization' (there are other type of plugins like completely separated apps) and registering it in the following way:

\begin{lstlisting}
export default function (kibana) {
	
	return new kibana.Plugin({
		uiExports: {
			visTypes: [
				'plugins/sprint2_plugin/sprint2']}})};
\end{lstlisting}

\end{itemize}

In order to define a basic functionality showing up "Hello World" inside the visualization plugin, we have to define the following two files also in directory public:

\begin{itemize}

\item sprint2.js. In this file, we define our visualization setting parameters like a title, a description or an icon to appear in visualization list. We also define here the controller for our div in Kibana, which we will describe in the next paragraph. Full code can be seen in appendix xxx(sprint2.js)

\item sprint2.html. In this file, a basic div is defined. It is defined as a controller, so a basic angularJS structure is used to attach a parameter named 'name' and show it in Kibana through the template. 
\end{itemize}

In figure \ref{fig:hello-world-menu-vis} our first visualization plugin can be seen in the list, together with default Kibana visualization plugins. Figure \ref{fig:hello-world-plugin} shows the final plugin result. With this basic plugin, we have the skeleton to build everything we want.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/hello-world-menu-vis}
  \caption{Hello World plugin in visualizations plugin list}
  \label{fig:hello-world-menu-vis}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/hello-world-plugin}
  \caption{Hello World plugin result}
  \label{fig:hello-world-plugin}
\end{figure}

Once plugin creation and interaction with elasticsearch from Kibana is clear, the next logical step is to incorporate our visual libraries in a plugin in Kibana. In this Sprint a basic threeDC scene will be created and correctly integrated in a visualization plugin in Kibana. No elasticSearch data will be used yet.

In order to progressively move toward the objective, a basic three.js scene will be integrated before integrating a more complex threeDC.js scene.

\subsection{Three.js scene integration}
\label{subsec:threejsint}

In order to insert a basic three.js scene in Kibana, the following steps were followed:

\begin{enumerate}

\item Add three.js library through node package manager.
To add three.js library is easy because it is already packed online (https://www.npmjs.com/package/three) and ready to install via npm simply with the 'npm install three' command.

\item From the main plugin file, the new library can easily be imported:

\begin{lstlisting}
THREE = require("three");
\end{lstlisting}

Then, it can be used across this file wherever we consider

\item A controller has been created manipulating a basic three.js rotating cube:

\begin{lstlisting}
module.controller('3DCubeController', function($scope, $element){

    init();
    animate();

    function init() {
        camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 1, 10000);
        camera.position.z = 1000;
        scene = new THREE.Scene();
        geometry = new THREE.BoxGeometry(200, 200, 200);
        material = new THREE.MeshBasicMaterial({
            color: 0xff0000,
            wireframe: true});
        mesh = new THREE.Mesh(geometry, material);
        renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        var idchart = $element.children().find(".3Dcubechart");
   		container = idchart[0];
        container.appendChild(renderer.domElement);}

    function animate() {
        requestAnimationFrame(animate);
        mesh.rotation.x += 0.01;
        mesh.rotation.y += 0.02;
        renderer.render(scene, camera);}});
\end{lstlisting}

The key in correctly inserting the scene in Kibana is in using the \$element service\footnote{\url{https://docs.angularjs.org/api/ng/function/angular.element}}, as it can be seen in the controller declaration in the code above. This angularJS service allows us to access jQuery functions from the controller. So jQuery functions children() and find() are used in order to find the correct div to insert in. Once found, all the scene is inserted here by using the appendChild HTML DOM manipulation function and the DOM element containing the scene returned from the renderer itself.

\item And in the main html file a canvas is defined to be controlled by the controller, and to contain a div to be found by jQuery service \$element.


\begin{lstlisting}
<canvas id="glcanvas" width="640" height="480" ng-controller="3DCubeController">
	   	<div class="3Dcubecontainer">
		<div class="3Dcubechart"> </div>
		</div>
</canvas>
\end{lstlisting}

The final result can be seen in Figure \ref{fig:only-threejsprueba}

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/only-threejsprueba}
  \caption{Three.js scene correctly inserted in Kibana}
  \label{fig:only-threejsprueba}
\end{figure}

\end{enumerate}

\subsection{ThreeDC.js scene integration}
\label{subsec:threedcjsint}

---------------------------------
Modulos en Javascript
Explicar sobre los módulos. 
vr vis es un modulo AMD. Necesita estar wrapped en define(function(require) ...)
ver https://www.timroes.de/2015/12/02/writing-kibana-4-plugins-simple-visualizations/
---------------------------

This section may seem obvious, but it's very tricky. ThreeDC.js library, in order to work properly, needs a set of external libraries itself. These modules are extensions that allow different functionality to the threeDC scene, like adding mouse interactivity or providing threejs fonts or text operations. We won't get into detail at this point, as threeDC already uses all these modules and it's not something new to this project.

Everythig would be easy if we could just include these files in the html. There would be a global variables scope where all of them would be attached and would be working properly. This is what threeDC.js library does. But in Kibana this can not be done, because everything is a module and all the variables have a scope. So, in order to solve this, we have to examine how exactly each one of these modules work and what they do.

The majority of these auxiliary modules simply extend the THREE object we already have from the library, by adding another property to this object. In these cases, by simply doing a require() of that file, the THREE object is correctly extended.

\begin{lstlisting}
  require("plugins/3D_kibana_charts_vis/FontUtils");
  require("plugins/3D_kibana_charts_vis/TextGeometry");
  require("plugins/3D_kibana_charts_vis/Projector");
  require("plugins/3D_kibana_charts_vis/OrbitControls");
\end{lstlisting}

Another case is that in the auxiliary modules a new object is created. In these cases, a simple require() is not enough. We have to export the object from inside the file with module.exports, so that it can correctly be imported from our main file. This is the case even with the threeDC library itself.

\begin{lstlisting}
 THREEDC = require("plugins/3D_kibana_charts_vis/3dc");
 THREEx = require("plugins/3D_kibana_charts_vis/threex.domevents");
 Detector = require("plugins/3D_kibana_charts_vis/Detector");
\end{lstlisting}

Also, helvetiker bold font has to be imported and loaded as follows. It is necessary for threeDC to work properly and correctly display text in the 3D scene.

\begin{lstlisting}
  var typeface2 = require('plugins/3D_kibana_charts_vis/helvetiker_bold.typeface');
  THREE.typeface_js.loadFace(typeface2);
\end{lstlisting}

Once imported all these modules, any threeDC scene can be created and displayed. In our case, we want to build the first 3D Pie chart scene integrated in Kibana. Once the scene is initialized, it is easy to create a pie, following the scheme described in the previous section \ref{subsec:threejsint}. We only need to create a pieChart threeDC Object inside our controller, add some sample data to it and display it:

\begin{lstlisting}
pie = THREEDC.pieChart();
pie.data(sampleData);
\end{lstlisting}

The visual result is very similar to what can be seen in Figure \ref{fig:onlypie3D}.

\section{Sprint 3: Working with data}

So far we have a very basic 3D pie visualization. From this basic scheleton we can built all the advanced functionality we want the pie to have, and also build the other visualizations (bars chart and bubbles chart) using this same structure.

In this Sprint, we focus on data treatment. Sample data will no longer be used, but elasticSearch queries will enter into action instead and get that data. This data is properly transformed in javascript in order to follow the pie chart input format, and then plot or replot the pie.

This data treatment is done in similar ways in the three visualizations developed in this plugin: pie chart, bars chart and bubbles chart, with minor differences. The duplicated functionality won't be repeated here, but a generalization on how to retrieve and treat the data for the pie chart will be given, which will serve for all the visualization charts.

\subsection{Defining the schemas}

After creating our first pie visualization with its visualization provider, a very important step is to define our schemas. Before writing any code, we should already know what kind of bucket and metrics aggregations it is needed for each chart type. Conceptually, the next schemas design has been made for the pie chart: it is needed exactly one bucket aggregation to define the slices and exactly one metric aggregation to define the slice size. With this in mind we define the schemas in the following way in our pie3D.js file:

\begin{lstlisting}
schemas: new Schemas([
        {
          group: 'metrics',
          name: 'slice_size',
          title: 'Slice Size',
          min: 1,
          max: 1,
          aggFilter: ['count', 'avg', 'sum', 'min', 'max', 'cardinality', 'std_dev']},
        {
          group: 'buckets',
          name: 'slices',
          title: 'Slices',
          min: 1,
          max: 1,
          aggFilter: '!geohash_grid'}])
\end{lstlisting}

Each Schemas object takes an array of objects in its constructor. Each object describes one aggregation that will be accepted for the pie visualization. Each aggregation object have the following keys:

\begin{itemize}

\item group - either "metrics" or "buckets". It defines which kind of aggregation we want to describe in this object.
\item name - the id of this aggregation. This will be used later by our controller to reference this aggregation.
\item title - the title shown to the user, when he adds the aggregation. Should describe how that aggregation will be visualized (e.g. in that case the bucket aggregation will create tags, the metrics aggregation will influence the tag size)
\item min/max - the number of minimum and maximum aggregations of that type, a user can add. In our case we only allow 1 aggregation of each type, due to the way our visualization works.
\item aggFilter - a filter on which aggregations should be allowed. It is an array of either aggregation types (see below), that are allowed in this place (as shown in our metrics aggregation) or an array of aggregation types forbidden (each must be prefixed with a bang). In the later case all other aggregations are allowed. If the array has only one element that can also be specified as a string (as shown in the bucket aggregation).
\end{itemize}

This schemas defined for the pie chart can be seen in actions in the pie aggregations menu, Figure \ref{fig:pie-aggregations-menu}.

For the bars and bubbles chart similar schemas have been defined. The bars chart defines exactly two buckets, one for each axis, and one metric, for each bar height. The bubbles chart also define these two buckets for each dimension and a metric for the bubble height, but it defines an extra metric for the bubble's size. That makes two buckets and two metrics in total.

\subsection{Data retrieval}

Once our schemas are correctly defined, we can access data from the controller by accesing two variables inherited into our angular scope.One is the vis variable, which holds information about your visualization and the settings the user chose. The other variable is named esResponse and holds the Elasticsearch response for your visualization. Kibana will automatically query Elasticsearch with the aggregations set by the user and taking into account currently set queries and filters.

To visualize our data we need to match the response data with the user configuration for our widget. To access the result of the aggregations we can look into \$scope.esResponse.aggregations. To find aggregations in that object we need their ids. To find the ids for a specific aggregation we can use several methods of \$scope.vis.aggs to find the id.

\begin{lstlisting}
      // Retrieve the id of the configured tags aggregation
      var slicesAggId = $scope.vis.aggs.bySchemaName['slices'][0].id;
      // Retrieve the metrics aggregation configured
      var metricsAgg = $scope.vis.aggs.bySchemaName['slice_size'][0];
      // Get the buckets of that aggregation
      var buckets = resp.aggregations[slicesAggId].buckets;
\end{lstlisting}

The buckets variable is an array of buckets, and accesing the key field of each bucket we get the bucket name which we can use to display each slice name. In order to get the value of that bucket, we access it in the following way:

\begin{lstlisting}
var value = metricsAgg.getValue(bucket);
\end{lstlisting}

This value will be used to determine each slice's size in the pie chart.

Similar reasoning can be made for the bars and the bubbles chart, with the following particularities:

\begin{itemize}
\item In order to get the second buckets aggregation id, we retrieve the second element of the \$scope.vis.aggs.bySchemaName['...'], like this:

\begin{lstlisting}
var barsyAggId = $scope.vis.aggs.bySchemaName['bars'][1].id;
\end{lstlisting}

A similar reasoning goes for retrieving the second metric aggregation. Then, we just have to apply the getValue method on each metrics aggregation.

\item In order to get the buckets in the 'y' dimension, we access each bucket in the 'x' dimension and then retrieve its buckets, like this:

\begin{lstlisting}
var bucketsy = bucketx[barsyAggId].buckets;
\end{lstlisting}

\end{itemize}

\subsection{Data treatment for threeDC}

So far we have managed to make kibana query elasticsearch for all the data we need to plot the charts. But this is not all the work it is need to be done. Some tedious work is still to be performed. This work consists in taking the data from the Kibana buckets and metrics aggregations and adapt it to the threeDC format.

We won't get into detail of how these algorythms were performed, but buckets and metrics have been treated in Javascript in order to get key-value pairs, in the format threeDC expects it. In the case of the pie chart, only one key and one value have been necessary to extract from the buckets and metrics, putting them in an ordered array of pair of this type.

For the bars chart and bubbles chart, similar data algorythms have been used, but this time each element in the array had more than one key or more than one value. It was important to keep the order in this array, that is, to go row by row in the data. Otherwise, threeDC library fails to plot it.

\section{Sprint 4: Kibana integration}

In this section, how filters were implemented will be explained. This Sprint has not been performed only at the end of this project, but things have been carefully studied in order to get this Kibana integration running smoothly. For example, we played with char dimensions, bugs were reported to threeDC library and fixed, and investigation have been made on the go in order to explore the possibility and reach of these filters.

In order to apply a filter function to a threeDC object, a mouse event is bind to that object, in the following way:

\begin{lstlisting}
dash.domEvents.bind(mesh, 'mousedown', function(object3d){
	//filter function code
});
\end{lstlisting}

It is also worth mentioning that filters are smart: they detect if the clicked slice, bar or bubble is representing a date or simply another type of field in order to implement a normal field filter or a time filter. This is done simply by inspecting the format of that field and launching one filter function or the other.

\subsection{Field filters}

The plugin supports adding field filters on click, that is, when a slice or bar or bubble is clicked, the corresponding filters are added in Kibana. This is done by using the filter manager service. This is found in ui\/filter\_manager directory of Kibana, and it has to be instantiated using the Private service to instantiate the filter service, which is responsible for instantiating angular services from required modules.

\begin{lstlisting}
	var filterManager = Private(require('ui/filter_manager'));
\end{lstlisting}

Next, the add function of this service can be used. Let's take a look at its implementation in the 3D pie controller for example. Each field is explained in the code commentaries.
\begin{lstlisting}
    filterManager.add(
    // The field to filter for, we can get it from the config
    $scope.vis.aggs.bySchemaName['slices'][0].params.field,
    // The value to filter for, we will read out the bucket key
    mesh.data.key,
    // Whether the filter is negated. If you want to create a negated filter pass '-' here
    null,
    // The index pattern for the filter
    $scope.vis.indexPattern.title
    );
\end{lstlisting}

\subsection{Date filters}

The previous function only adds "normal" filter, it doesn't manage time ranges and much less it adds it directly to the Kibana time filter. Many lines of code have been read until the next solution came to solve this problem. The process is explained in the next paragraphs:

\begin{enumerate}
\item First of all, dates need to be managed in the javascript code. We used the 'moment' library in order to perform actions such as interpreting different text time formats, adding intervals to time expressed in different units or constructing moment objects that represent time.

\begin{lstlisting}
    var from = moment(mesh.data.key);
    var interval = moment($scope.slices[1].key) - moment($scope.slices[0].key);
    var to = moment(from).add('ms', interval);
\end{lstlisting}

\item The rootScope service has been used in order to access timefilter fields in Kibana. Once done, we can assign them our own calculated values for time.

\begin{lstlisting}
    $rootScope.$$timefilter.time.from = from;
    $rootScope.$$timefilter.time.to = to;
    $rootScope.$$timefilter.time.mode = 'absolute';
\end{lstlisting}
\end{enumerate}

\subsection{Dashboard}

As it has been previously said, in order to correctly view our visualizations in a dashboard, nothing special was done in this sprint but to carefully build the visualizations so that integrate well when using the dashboard page (for example, taking care to refresh the charts when new data had been retrieved, or naming the divs accordingly in order to get independability). The final result can be seen in figure \ref{fig:3Ddashboard}.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/3Ddashboard}
  \caption{Built dashboard showing the 3 developed visualizations at the same time}
  \label{fig:3Ddashboard}
\end{figure}

In this dashboard, we can apply filter by clicking a slice, a bar or a bubble. We can also apply filters in the Kibana way, of course: by touching the top right time filter or adding a filter manually in the filter bar. When we apply a filter, all charts correctly refresh in order to show the new data. Kibana default visualizations can be added in the dashboard and it integrates with the 3D charts fluently.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RESULTADOS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Design and results}

\section{Introduction}

In this chapter the final aspects and usability of the plugin will be exposed. In first place, a complete architecture of the final plugin is given. Next, a full user guide is given in order to explain in detail every feature of the plugin from a user's view.
\section{Architecture}

In figure \ref{fig:3dcharts-architecture} the final architecture of this plugin is displayed. Many of these files have been already explained across this paper.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/3dcharts-architecture}
  \caption{Plugin's file architecture}
  \label{fig:3dcharts-architecture}
\end{figure}

\section{User Guide}

In this section every functionality of the plugin will be explained. A detailed guide on how to produce each type of visualization will be given, as welll as every possibility every visualization type has.

After correctly installing the plugin, three new visualizations type should be available in the Kibana Visualizations menu, as shown in Figure \ref{fig:my3viz-inmenu}


\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/my3viz-inmenu}
  \caption{The 3 new plugin visualizations in Kibana menu}
  \label{fig:my3viz-inmenu}
\end{figure}

Next, each visualization and its functionalities will be explained separately.

\subsection{3D Pie Chart}

After selecting "3D Pie Chart" in the menu and selecting the index pattern to work with (Kibana asks for it), we come across with the 3D pie aggregations menu, as seen in Figure \ref{fig:pie-aggregations-menu} borded with a red rectangle.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/pie-aggregations-menu}
  \caption{3D Pie visualization aggregations menu}
  \label{fig:pie-aggregations-menu}
\end{figure}

The 3D pie visualization needs exactly one buckets aggregations and one metrics aggregation. By clicking on 'Slices' we are choosing what each slice of our pie will represent, the buckets in which our data will fall into. We could choose, for example, a Date Histogram, and then each slice will represent a date interval. By clicking on 'Slice Size' we are choosing what the size of each slice means, the metrics of the data. For example, we could choose the 'Count' aggregation, in which case the size of each slice will be determined by the number of documents that fall into each bucket.

The result of such an example can be seen in Figure \ref{fig:onlypie3D}. When the mouse moves over a slice, info about that slice is displayed:
\begin{itemize}
	\item \textbf{key}: shows the bucket which that slice represents
	\item \textbf{value}: shows the metric we configured in aggregations menu
\end{itemize}

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/onlypie3D}
  \caption{3D pie}
  \label{fig:onlypie3D}
\end{figure}

\subsection{3D Bars Chart}

After selecting "3D Bars Chart" in the menu and selecting the index pattern to work with, we come across with the 3D bars aggregations menu, as seen in Figure \ref{fig:bars-aggregations-menu} borded with a red rectangle.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/bars-aggregations-menu}
  \caption{3D Bars visualization aggregations menu}
  \label{fig:bars-aggregations-menu}
\end{figure}

The 3D bars visualization needs exactly two buckets aggregations and one metric aggregation. The first buckets aggregation is for the values in X axis and the second buckets aggregation is for the Y axis. For example, we could choose to group our date in X axis by a Date Histogram, and then in Y axis by some Terms. We define these by clicking on the 'Bars' button and remembering to click the 'Add sub-buckets' button to define the Y axis. We define the height of each bar by defining the metric clicking on 'Bars Height'. For example, we could choose the 'Count' aggregation to represent the number of documents found in that bucket by the height of the 3D Bar.

The result of such an example can be seen in Figure \ref{fig:onlybars3D}. When the mouse moves over a bar, info about that bar is displayed:
\begin{itemize}
	\item \textbf{key1}: shows the first bucket id previously defined in aggregations menu
	\item \textbf{key2}: shows the second bucket id previously defined in aggregations menu
	\item \textbf{value}: shows the metric we configured in aggregations menu
\end{itemize}

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/onlybars3D}
  \caption{3D bars chart}
  \label{fig:onlybars3D}
\end{figure}


\subsection{3D Bubbles Chart}

After selecting "3D Bubbles Chart" in the menu and selecting the index pattern to work with, we come across with the 3D bubbles aggregations menu, as seen in Figure \ref{fig:bubbles-aggregations-menu} borded with a red rectangle.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/bubbles-aggregations-menu}
  \caption{3D Bubbles visualization aggregations menu}
  \label{fig:bubbles-aggregations-menu}
\end{figure}

The 3D bubbles visualization needs exactly two buckets aggregations and two metric aggregation. The first buckets aggregation is for the values in X axis and the second buckets aggregation is for the Y axis. For example, we could choose to group our date in X axis by a Date Histogram, and then in Y axis by some Terms. We define these by clicking on the 'Bubbles' button and remembering to click the 'Add sub-buckets' button to define the Y axis.

We define each bubble's height and size clicking the metric 'Bubbles Height and Size'. For example, we could choose the 'Average' metric on some field in first place to establish each bubble's height and then the 'Count' metric to establish each bubble's size.

The result of such an example can be seen in Figure \ref{fig:onlybubbles3D}. When the mouse moves over a bubble, info about that bubble is displayed:
\begin{itemize}
	\item \textbf{key1}: shows the first bucket id previously defined in aggregations menu, represented in X axis
	\item \textbf{key2}: shows the second bucket id previously defined in aggregations menu, represented in Y axis
	\item \textbf{value}: shows the first metric we configured in aggregations menu, represented bubble's height
	\item \textbf{value2}: shows the metric we configured in aggregations menu, represented in bubble's size
\end{itemize}

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/onlybubbles3D}
  \caption{3D Bubble chart}
  \label{fig:onlybubbles3D}
\end{figure}


\subsection{Interacting with the 3D charts}

In this section we will explain what charts can do once built and how the user can interact with the 3D scene. 

In first place, scene can be zoomed in or zoomed out using the mouse wheel. It can also be dragged used the secondary mouse button and rotated using the principal mouse button and moving the mouse.

In second place, in each of the charts, when mousing over a slice, bar or bubble, the object it's visually highlighted. Additionally, when clicking on a particular object, the corresponding filters automatically apply filtering for the buckets defined. In this way, we have only one filter applied when clicking on a slice in the pie chart, and two filters applied when clicking on a bar in the bars chart or a bubble in the bubbles chart. The filter applied automatically know if they should apply a time filter, as if the user manually defined it in the right top corner, or just apply a normal field filter.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONCLUSIONES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Conclusions}
\label{chap:conclusions}

\section{Objectives achievement}
\label{sec:consecucion-objetivos}

We can say that we fullfilled the objectives established for this project. We have successfully integrated 3D charts in Kibana.

Some 3D charts have been added to Kibana in the form of new visualizations appearing in its menu. Finally, we have managed to integrate 3 different types of 3D visualizations: a 3D pie chart, a 3D bars chart and a 3D bubbles chart. Maybe I could have added one or two more, but I decided they were not so interesting and didn't contemplate this possibility.

In second place, a lot of work has been done with threedc.js. We have to remind here that this was a very new technology developed by a student, and using this library for the first time in another system was both challenging and dangerous. Somo blocking issues have appeared along this project with the library. Luckily, I was close in touch with the developer and he acceeded to my petitions to correct bugs, improve some functionalities and even add new functionalities! We have agreed for example to introduce customizable filters to the scenes.

Another challenging issue was to work with such a fairly new tool as Kibana is. Particularly, what was really complicated is to develop a plugin for this system, as there is no official documentation on how to do it, and things even get broken when there is some release. This was not clear at all and I had to figure out what the problem was by myself, as I upgraded Kibana several times through the developing of this plugin. To get an idea of the difficulty of this task, I have to mention I have spent in one occasion more than a week to write the exact three lines of code I needed (this happened with the time filter), after a large research and contacting other developers.

In the moment this paper is written, the plugin is already officially recognized by the elastic team and published in their list of known plugins\footnote{\url{https://www.elastic.co/guide/en/kibana/current/known-plugins.html}}. The project has been published only about two weeks ago and is starting to be tested and used by the community. So far, 29 people have successfully cloned the project, and about 500 people have taken a look to the project itself. Two weeks is a very short time, and traffic is expected to grow as the project gains popularity across the community.

\section{Application of lessons learned}
\label{sec:aplicacion}

Although I have coursed 63 assignments in my career, not so many of them have been used to develop this project. But there is no doubt I have used many concepts and habilities acquired through assignments such as "Programming Fundamentals", "Telematic Systems I", "Telematics Systems II", "Bases of Programming Languages", "Programming Methodology", "Object Oriented Programming", "Telematic Applications and Systems", "Software Engineering", "Database Design" and "Multimedia, Interactive, Distributed and Scalable Applications". They have all offered me a great view of a great number of technologies, earning at the same time precious abilities so that this project didn't seem overwhelming.

At the same time, I have to mention that Javascript language was almost unknown to me, and we only touched this programming language in one or two clases. This was one of my difficulties in this project, as I had to learn all the Javascript syntax and particularities on my own.

\section{Lessons learned}
\label{sec:lecciones_aprendidas}

I can say I have learned the following skills through this project, ordered from the most important and challenging to the less important:

\begin{itemize}

\item Javascript programming language from zero. HTML5 and AngularJS.
\item Use of the open source tool of data visualization and dashboard Kibana, as well as to
develop for this tool and to fit to its peculiarities.
\item Solving different programming issues just by reading source code written by others
\item Improvement of my abilites in the programming community: advanced use of github, communicating with other developers through official forums
\item Knowledge of a non-relational database system and its syntax: ElasticSearch
\item Use of \LaTeX by developing the degree thesis, an interesting  document preparation system.
\end{itemize}


\section{Future work}
\label{sec:trabajos_futuros}

We have reached our main goals, but there is still work that can be done to improve it. I will mention some guidelines on some new or improved features:

\begin{itemize}

\item Add some more 3D charts
\item Work with the scene dimensions in order to adapt it to each screen, as well as playing with the size and centering of the graphs to adjust them perfectly when initializing them in a Kibana dashboard
\item Adding extra options to show to user, such as choosing different interesting scene parameters: chart colors, number of sources of light, materials opacity, etc
\item Investigate and improve performance. At the moment, when displaying more than one scene specially, the dashboard begins to move quite slowly the scene when having a lot of data.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APÉNDICE(S) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\appendix
\label{sec:appendix}
\chapter{Appendix}

\section{index.html from Sprint1}

Complete index.html file from Sprint 1

\begin{lstlisting}[frame=single]
<!DOCTYPE html>
<html>
	<head>
		<title>Threeboard</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<link rel="stylesheet" type="text/css" href="node_modules/bootstrap/dist/css/bootstrap.css">
	</head>
	<body ng-app="ExampleApp">
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r78/three.min.js"></script>
		<script src="js/FontUtils.js"></script>
		<script src="js/TextGeometry.js"></script>
		<script src="js/Projector.js"></script>
		<script src='js/threex.domevents.js'></script>
		<script src="js/Detector.js"></script>
		<script src="js/Stats.js"></script>
		<script src="js/OrbitControls.js"></script>
		<script src="js/THREEx.WindowResize.js"></script>
		<script src="js/THREEx.FullScreen.js"></script>
		<script type="text/javascript" src='js/DAT.GUI.min.js'></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/crossfilter/1.3.12/crossfilter.min.js"></script>
		<script src="js/3dc.js"></script>
		<div id="ThreeJS" style="position: absolute; left:0px; top:0px">
		<script src="fonts/gentilis_bold.typeface.js"></script>
		<script src="fonts/gentilis_regular.typeface.js"></script>
		<script src="fonts/optimer_bold.typeface.js"></script>
		<script src="fonts/optimer_regular.typeface.js"></script>
		<script src="fonts/helvetiker_bold.typeface.js"></script>
		<script src="fonts/helvetiker_regular.typeface.js"></script>
		<script src="fonts/droid_sans_regular.typeface.js"></script>
		<script src="fonts/droid_sans_bold.typeface.js"></script>
		<script src="fonts/droid_serif_regular.typeface.js"></script>
		<script src="fonts/droid_serif_bold.typeface.js"></script>

  <!-- include npm modules in proper order -->
  <script src="node_modules/angular/angular.min.js"></script>
  <script src="node_modules/elasticsearch-browser/elasticsearch.angular.min.js"></script>
		<script src="script.js"></script>

  <!-- attach the ExampleController to our main content -->
  <div ng-controller="ExampleController" class="container">
    <h1>Angular + Elasticsearch</h1>

    <!-- if there is an error, display its message -->
    <div ng-if="error" class="alert alert-danger" role="alert">{{error.message}}</div>

    <!-- if clusterState is available, display it as formatted json -->
    <div ng-if="clusterState" class="panel panel-default">
      <div class="panel-heading">
        <h3 class="panel-title">Cluster State</h3>
      </div>
      <div class="panel-body">
        <pre>{{clusterState | json}}</pre>
      </div>
    </div>
  </div>

	</body>
</html>
	</body>
</html>
\end{lstlisting}

\section{script.js from Sprint1}
\label{sec:script.js}

\begin{lstlisting}[frame=single]

// standard global variables
var container, scene, camera, renderer, stats;

//JSON data saved here
var json_data;


 elasticstuff();

// initialization
  //getJSON call, draw meshes with data
   $.getJSON("jsons/scm-commits.json", function(data) {
      json_data=data;
      init();
      // animation loop / game loop
      animate();
   });

///////////////
// FUNCTIONS //
///////////////

function elasticstuff() {
  //elasticsearch and angular
    // App module
    //
    // The app module will contain all of the components the app needs (directives,
    // controllers, services, etc.). Since it will be using the components within
    // the elasticsearch module, define it a dependency.
    var ExampleApp = angular.module('ExampleApp', ['elasticsearch']);

    // Service
    //
    // esFactory() creates a configured client instance. Turn that instance
    // into a service so that it can be required by other parts of the application
    ExampleApp.service('client', function (esFactory) {
      return esFactory({
        host: 'localhost:9200',
        apiVersion: '2.3',
        log: 'trace'
      });
    });

    // Controller
    //
    // It requires the "client" service, and fetches information about the server,
    // it adds either an error or info about the server to $scope.
    //
    // It also requires the esFactory to that it can check for a specific type of
    // error which might come back from the client
    ExampleApp.controller('ExampleController', function ($scope, client, esFactory) {

      client.cluster.state({
        metric: [
          'cluster_name',
          'nodes',
          'master_node',
          'version'
        ]
        })
      .then(function (resp) {
        $scope.clusterState = resp;
        $scope.error = null;
      })
      .catch(function (err) {
        $scope.clusterState = null;
        $scope.error = err;

        // if the err is a NoConnections error, then the client was not able to
        // connect to elasticsearch. In that case, create a more detailed error
        // message
        if (err instanceof esFactory.errors.NoConnections) {
          $scope.error = new Error('Unable to connect to elasticsearch. ' +
            'Make sure that it is running and listening at http://localhost:9200');
        }
      });

    });
}

function init () {

   ///////////
   // SCENE //
   ///////////
   scene = new THREE.Scene();

   ////////////
   // CAMERA //
   ////////////
   // set the view size in pixels (custom or according to window size)
   var SCREEN_WIDTH = window.innerWidth/2;
   var SCREEN_HEIGHT = window.innerHeight/2;
   // camera attributes
   var VIEW_ANGLE = 45;
   var ASPECT = SCREEN_WIDTH / SCREEN_HEIGHT;
   var NEAR = 0.1;
   var FAR = 20000;
      // set up camera
   camera = new THREE.PerspectiveCamera( VIEW_ANGLE, ASPECT, NEAR, FAR);
   // add the camera to the scene
   scene.add(camera);
   // the camera defaults to position (0,0,0)
   //    so pull it back (z = 400) and up (y = 100) and set the angle towards the scene origin
   camera.position.set(0,150,400);
   camera.lookAt(scene.position);

   //////////////
   // RENDERER //
   //////////////
   renderer = new THREE.WebGLRenderer( {antialias:true} );
   renderer.setSize(SCREEN_WIDTH, SCREEN_HEIGHT);
   renderer.setClearColor( 0xd8d8d8 );

   // attach div element to variable to contain the renderer
   container = document.getElementById( 'ThreeJS' );
   // attach renderer to the container div
   container.appendChild( renderer.domElement );

    ////////////
  // EVENTS //
  ////////////



  // automatically resize renderer
  THREEx.WindowResize(renderer, camera);
    // toggle full-screen on given key press
  THREEx.FullScreen.bindKey({ charCode : 'm'.charCodeAt(0) });

   ///////////
   // LIGHT //
   ///////////
   var light = new THREE.PointLight(0xffffff,0.8);
   light.position.set(0,200,250);
   scene.add(light);
   var ambientLight = new THREE.AmbientLight(0x111111);
   // scene.add(ambientLight);

   // create a set of coordinate axes to help orient user
   //    specify length in pixels in each direction
   var axes = new THREE.AxisHelper(1000);
   scene.add(axes);

  //STATS
  stats = new Stats();
  stats.domElement.style.position = 'absolute';
  stats.domElement.style.bottom = '0px';
  stats.domElement.style.zIndex = 100;
  container.appendChild( stats.domElement );

   //////////////
   // CUSTOM //
   //////////////

   // most objects displayed are a "mesh":
   //  a collection of points ("geometry") and
   //  a set of surface parameters ("material")

  var parsed_data=[];

  // Crossfilter and dc.js format
  json_data.values.forEach(function (value) {
    var record = {}
    json_data.names.forEach(function (name, index) {
        if (name == "date") {
          var date = new Date(value[index]*1000);
          record[name] = date;
          record.month = new Date(date.getFullYear(), date.getMonth(), 1);
          record.hour = date.getUTCHours();
        } else {
          record[name] = value[index];
        }
    });
    parsed_data.push(record);
  });

  //example data for cloud

  function getRandomPoints(numberOfPoints){
    var points=[];
    for (var i = 0; i < numberOfPoints; i++) {

      points[i]={x:Math.random()*100,y:Math.random()*100,z:Math.random()*100};
     // console.log(points[i]);
    };
    return points;
  }

 //CUSTOM DASHBOARD//

  THREEDC.initializer(camera,scene,renderer,container);

  var cloud= THREEDC.pointsCloudChart([0,0,0]);
  cloud.getPoints(getRandomPoints(1000));

 // var bars= THREEDC.barsChart([0,0,0]);
  //bars.group(groupByRepo);

  THREEDC.renderAll();

}

function animate()
{
   requestAnimationFrame( animate );
   render();
   update();
}

function render()
{
   renderer.render( scene, camera );
}

function update()
{
  THREEDC.controls.update();
  stats.update();
  
\end{lstlisting}[frame=single]

\section{sprint2.js from Sprint2}
\label{sec:sprint2.js}


\begin{lstlisting}[frame=single]

  // Create an Angular module for this plugin
  var module = require('ui/modules').get('sprint2');
  // Add a controller to this module
  module.controller('HelloController', function($scope, $timeout) {

    $scope.name="Viorel Rusu"

  });


export default function Sprint2Provider(Private) {
    var TemplateVisType = Private(require('ui/template_vis_type/template_vis_type'));
    return new TemplateVisType({
      name: 'Sprint2', // the internal id of the visualization
      title: 'Sprint2', // the name shown in the visualize list
      icon: 'fa-hand-spock-o', // the class of the font awesome icon for this
      description: 'Basic hello world plugin', // description shown to the user
      requiresSearch: false, // Cannot be linked to a search
      template: require('plugins/sprint2_plugin/sprint2.html') // Load the template of the visualization
    });
  }

  require('ui/registry/vis_types').register(Sprint2Provider);
  
\end{lstlisting}[frame=single]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFIA %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Bibliography}
\label{sec:bib}

\begin{enumerate}
\item Scrum:
\url{http://scrummethodology.com/scrum-sprint/}

\item Javascript:
 Marijn Haverbeke, \textit{Eloquent JavaScript}. 2014

\url{http://www.w3schools.com/js/}

\item Node and npm:
\url{https://www.sitepoint.com/beginners-guide-node-package-manager/}

\item Angular:
\url{http://campus.codeschool.com/courses/shaping-up-with-angular-js}
\url{https://www.toptal.com/angular-js/a-step-by-step-guide-to-your-first-angularjs-app}
\url{http://www.w3schools.com/angular/}

\item Kibana plugins:
\url{https://www.timroes.de/2015/12/02/writing-kibana-4-plugins-basics/}
\url{https://www.timroes.de/2015/12/02/writing-kibana-4-plugins-simple-visualizations/}
\url{https://www.timroes.de/2015/12/06/writing-kibana-4-plugins-visualizations-using-data/}
\url{https://www.timroes.de/2016/02/17/writing-kibana-4-plugins-field-formatters/}
\url{https://www.timroes.de/2016/02/21/writing-kibana-plugins-custom-applications/}

\item webGl:
\url{https://en.wikipedia.org/wiki/WebGL}
\url{https://www.chromeexperiments.com/experiment/webgl-water-simulation}

\item three
\url{https://github.com/mrdoob/three.js}
\url{http://helloracer.com/}

\item kibana and elasticsearch:
\url{https://www.elastic.co}

\end{enumerate}

\end{document}
